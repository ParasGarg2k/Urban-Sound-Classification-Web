# ğŸ§ Urban Sound Classification

This project aims to classify urban sound recordings into predefined categories using four deep learning models: **CNN**, **ResNet**, **Wave2Vec2**, and **AST (Audio Spectrogram Transformer)**. We compare their performances using multiple metrics and deploy a Streamlit web application for real-time predictions.

---

## ğŸ“Œ Table of Contents

- [ğŸ¯ Introduction](#-introduction)
- [ğŸ“ Dataset](#-dataset)
- [ğŸ› ï¸ Technologies Used](#-technologies-used)
- [ğŸ“Š Performance Comparison](#-performance-comparison)
- [ğŸ“ˆ Confusion Matrices](#-confusion-matrices)
- [ğŸ§ª Training & Testing Accuracy Graphs](#-training--testing-accuracy-graphs)
- [ğŸ§ª Training & Testing Loss Graphs](#-training--testing-loss-graphs)
- [ğŸ–¥ï¸ Web App Screenshots](#-web-app-screenshots)
- [ğŸ“„ Project Report](#-project-report)

---

## ğŸ¯ Introduction

Urban environments are full of distinctive soundsâ€”car horns, sirens, dog barks, drilling, etc. This project leverages deep learning techniques to classify such environmental audio samples from the **UrbanSound8K dataset**. The system can aid in **smart city solutions**, **noise pollution analysis**, and **automatic tagging systems**.

---

## ğŸ“ Dataset

- **UrbanSound8K**: 8732 labeled audio clips (â‰¤4s) from 10 urban classes.  
- [Download Link](https://urbansounddataset.weebly.com/urbansound8k.html)  
- Classes: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music  
- Preprocessing: MFCC, Mel-spectrogram, zero-padding

---

## ğŸ› ï¸ Technologies Used

- **Languages**: Python  
- **Audio**: Librosa, SoundFile  
- **Models**: TensorFlow, PyTorch, Hugging Face Transformers  
- **Visualization**: Matplotlib, Seaborn  
- **Web App**: Streamlit  
- **Other**: NumPy, Pandas, OpenCV

---

The models evaluated:
- ğŸ”· CNN (1D)
- ğŸŸ© ResNet (on Mel-spectrograms)
- ğŸŸª Wave2Vec2 (Facebookâ€™s pretrained speech model)
- ğŸŸ¨ AST (Audio Spectrogram Transformer)

---

## ğŸ“Š Performance Comparison
![Performance Comparison](images/comp.png)


---

## ğŸ“ˆ Confusion Matrices
![Confusion Matrices](images/conf.png)


---

## ğŸ§ª Training & Testing Accuracy Graphs
![Training & Testing Accuracy Graphs](images/acc.png)

---

## ğŸ§ª Training & Testing Loss Graphs
![Training & Testing Loss Graphs](images/loss.png)

---

## ğŸ–¥ï¸ Web App Screenshots
![Web App Screenshots](images/web.png)


---

## ğŸ“„ Project Report

The complete report detailing:
- Data preprocessing techniques (e.g., MFCC, Mel-Spectrograms)
- Model architecture for each approach
- Training parameters (batch size, optimizer, loss)
- Evaluation metrics (confusion matrix, precision, recall, F1)
- Challenges and future improvements

ğŸ“„ **[Download Report (PDF)](https://drive.google.com/file/d/11fzHFheMiMHPoa5fUgXUtKWEmnHu1PKq/view?usp=drive_link)**

---


